---
id: kibDevDocsHttpApiIaaCConsiderations
slug: /kibana-dev-docs/kibana-http-api-terraform-friendly-guidelines
title: Guidelines for Terraform friendly HTTP APIs
description: An introduction to what it means to be Terraform friendly, and how to design Kibana HTTP APIs with this in mind.
date: 2025-06-16
tags: ['kibana', 'dev', 'architecture', 'http']
---

Kibana's role has expanded beyond the UI. APIs have become the backbone for how customers automate their workflows, build custom scripts, and create their own integrations. With GitOps becoming the standard and Terraform establishing itself as the go-to infrastructure-as-code tool, HTTP APIs are now business-critical. The rise in Search AI means that it's more important than ever to make sure our APIs are easily understood by LLMs.

For Terraform to be a first class citizen, the provider needs to cover resources that weren't available before—think Dashboards, Visualizations, Data Views, and Detection Rules. This means we need to build REST APIs that follow the OpenAPI Specification properly, making it straightforward for teams to manage these resources as code through GitOps workflows.

These guidelines will help you build APIs that are easy to use, whether someone's automating with scripts or managing infrastructure at scale.

# Terraform Provider Developer-Friendly API Design

Terraform can work with any API, but some APIs are easier to deal with than others. Here are some tips to make your API more Terraform provider-friendly:

## Think in terms of resources

APIs that stick to a consistent set of arguments or parameters are much easier to map into Terraform. Terraform can describe the "thing" your API is managing. RPC-based APIs are harder to work with since they’re not declarative. Your HTTP APIs should describe REST-like actions (GET, POST, DELETE, etc.) against resources not remote procedures like: executeJob. 

APIs designed around resources are easier to support than those focused on action-oriented endpoints.

✅ Preferred: REST-like actions against resources

```
GET    /api/alerting/rule/{id}     # Kibana Alerting API
POST   /api/alerting/rule/{id}     # Create rule
PUT    /api/alerting/rule/{id}     # Update rule
DELETE /api/alerting/rule/{id}     # Delete rule
```

⚠️ Alternative: action-style endpoints

```
POST /api/executeJob
POST /api/processSpaceUpdate
POST /api/triggerIndexRebalance
```

Mapping resource-oriented APIs to a declarative model means users can describe the desired state rather than the steps to achieve it. While action-oriented endpoints sometimes become necessary, knowing the trade-offs helps you make informed decisions.

### Ideal

The [Index Lifecycle Management API](https://www.elastic.co/docs/api/doc/elasticsearch/operation/operation-ilm-put-lifecycle) (PUT /\_ilm/policy/{policy}) declaratively defines the desired lifecycle state rather than imperatively executing phase transitions:

```terraform
resource "elasticstack_elasticsearch_index_lifecycle" "my_ilm" {
  name = "my_ilm_policy"

  hot {
    min_age = "1h"
    rollover {
      max_age = "1d"
      max_size = "50g"
    }
  }

  delete {
    min_age = "60d"
    delete {}
  }
}
```

[ILM resource](https://github.com/elastic/terraform-provider-elasticstack/blob/main/docs/resources/elasticsearch_index_lifecycle.md)

### API imposed challenges

API design decisions can create real challenges for Terraform resource implementation. The Elasticsearch [Index Settings API](https://www.elastic.co/docs/api/doc/elasticsearch/operation/operation-indices-put-settings) (\`PUT /{index}/\_settings\`) treats static settings (which require index recreation) and dynamic settings (which can be updated in place) identically. This creates a complex situation forcing the implementation to handle all settings together because the API doesn't offer a way to distinguish them upfront. 

```bash
{
  "error": {
    "reason": "Can't update non dynamic settings [[index.codec, index.number_of_shards]] for open indices"
  
}
```

[Index Settings Update Bug](https://github.com/elastic/terraform-provider-elasticstack/issues/52)

A better API design would separate these concerns with different endpoints or provide metadata about which settings require recreation.

## Design human-friendly APIs

When humans can easily understand your API, machines can too. APIs with clear, descriptive field names and logical resource structures make both manual testing and Terraform resource development much smoother.

### When APIs Excel: Intuitive Field Names

Clear, descriptive field names translate to intuitive Terraform resources. Elasticsearch APIs generally follow this pattern, and we end up self-documenting configuration.

```terraform
resource "elasticstack_elasticsearch_index" "example" {
  name                    = "my-index"              # Obvious purpose
  number_of_shards       = 1                       # Self-documenting
  number_of_replicas     = 2                       # Clear meaning
  deletion_protection    = true                    # Prevent accidents
  search_idle_after      = "20s"                   # Human-readable duration
}
```

[Index Resource](https://github.com/elastic/terraform-provider-elasticstack/blob/main/docs/resources/elasticsearch_index.md)

#### Complex Configuration Handling

Complex mappings (e.g. saved objects) make life difficult but not impossible. One *can* make complex mappings readable through JSON encoding:

```terraform
mappings = jsonencode({
  properties = {
    user = {
      properties = {
        name = { type = "text" }
        age  = { type = "integer" }
      }
    }
  }
})
```

The difficulty lies with validation. Terraform is just not designed to do the validation or testing in the way a conventional language would. It doesn’t do string validation outside of the basic terraform plan which parses pass/fail, or if it does it will be awkward. Typically we fall back to the API layer for validation checks. Not being able to validate a resource configuration in terraform leads to repetitive plan/apply issues which is annoying to say the least\!

One has to do the [parsing and transforming](https://github.com/elastic/terraform-provider-elasticstack/tree/main/internal/elasticsearch/index/indices) of the data outside terraform and pipe it in and that is where you can do the checks. 

### Return errors early—and all at once

If your API can validate inputs upfront and return all the errors in one go, do it\! Terraform handles it and show them in a helpful way:

```go
var diags diag.Diagnostics
diags = append(diags, diag.Diagnostic{
    Severity: diag.Error,
    Summary:  "Invalid index setting",
    Detail:   "Setting 'codec' cannot be changed after index creation",
})
diags = append(diags, diag.Diagnostic{
    Severity: diag.Error,
    Summary:  "Invalid mapping change",
    Detail:   "Cannot change field datatype in existing mapping",
})
```

[Fleet Agent Policy Update](https://github.com/elastic/terraform-provider-elasticstack/blob/main/internal/fleet/agent_policy/update.go)

When validation only happens during execution, catching errors early becomes impossible. For example, ILM policy structure errors only surface during API calls:

```bash
Error: Failed to build [allocate] after last required field arrived
Detail: [allocate] exclude doesn't support values of type: VALUE_STRING
```

[ILM import issues](https://github.com/elastic/terraform-provider-elasticstack/issues/87)

The cost of not catching errors early is interrupted workflow, repetitive plan/apply failures and frustrated consumers.

#### No side effects during HTTP GET or read requests

Terraform might call \`refresh\` multiple times, and Terraform Cloud could do it even more. If your API creates objects, updates data, or does anything else during a GET request, you’re in for trouble. Terraform expects GET requests to be harmless and side-effect-free.

If you have to have side effects (like updating a ‘last-read’ timestamp), consumers have to work around it by, for example, limiting the number of times something’s read or building custom tooling to handle state drift.

#### Standardize Patterns Across Your API

Consistency is key for Terraform resource development. Using standard patterns make reusable abstractions and helper functions possible.

For example, all Elasticsearch resources use the same authentication patterns, whether you're working with indices, security roles, or lifecycle policies:

```terraform
provider "elasticstack" {
  elasticsearch {
    username  = "elastic"
    password  = "changeme"
    endpoints = ["http://localhost:9200"]
  }
}
```

[Provider configuration example](https://github.com/elastic/terraform-provider-elasticstack/blob/main/examples/provider/provider.tf)

OpenAPI specifications make generating consistent Kibana and Fleet clients possible:

```bash
# From Makefile - generates standardized clients
internal/clients/fleet/: 
	oapi-codegen -package fleet fleet-openapi.json
```

[Provider makefile](https://github.com/elastic/terraform-provider-elasticstack/blob/main/Makefile)

Standardization means authentication, error handling, and request patterns become reusable across all resources.

#### Return as Much Info as You Can, and handle defaults carefully

Terraform needs complete information to track resource state effectively. If your API doesn't return enough details, Terraform can't properly detect changes or manage drift.

**The Challenge with Defaults**

Many Kibana APIs have extensive configuration options. Requiring users to specify every single value would create verbose, unwieldy configurations. However, being too sparse with returned data creates problems for Terraform.

**The Golden Rule**

A resource returned from a GET request should match as closely as possible to what a user specifies in a PUT request. When users don't specify values that affect critical behavior, consider returning those computed values too.

**Why This Matters for Import Operations**

Terraform import brings existing resources under management by reading their current state. If your API returns different data than what users originally configured, it can cause [import state loss bugs](https://github.com/elastic/terraform-provider-elasticstack/issues/53).

```bash
# User creates resource with minimal config
POST /api/resource { "name": "my-resource" }

# API applies defaults internally
# name: "my-resource"
# timeout: 30s (default)
# retries: 3 (default)

# Later, GET returns only user-specified values
GET /api/resource/my-resource
{ "name": "my-resource" }

# Terraform can't detect if defaults changed!
```

**Handling Defaults Strategically**

Consider these approaches:

1. **Return computed defaults explicitly**
   ```json
   {
     "name": "my-resource",
     "timeout": "30s",      // Default applied
     "retries": 3,          // Default applied
     "user_specified": {    // Optional: track what user set
       "timeout": false,
       "retries": false
     }
   }
   ```

2. **Offer response control with query parameters**
   ```bash
   GET /api/resource/123?include_defaults=true
   GET /api/resource/123?minimal=true
   ```

3. **Separate user config from computed values**
   ```json
   {
     "config": {
       "name": "my-resource"  // User-specified only
     },
     "computed": {
       "timeout": "30s",      // Applied defaults
       "retries": 3
     }
   }
   ```

**The Import Problem**

When defaults aren't handled carefully, Terraform import operations can lose state. The imported resource might not match the original configuration, forcing users to make unnecessary changes or causing configuration drift.

Choose your approach based on your API's complexity, but prioritize consistency between what users send and what they receive back.

#### Be Predictable

Terraform relies on the same input resulting in the same output..  Avoid using fields like "last modified time"—Terraform can’t compare those meaningfully. This can be tricky with sensitive fields or when your API relies on randomness.  

Constantly changing fields in API responses create a difficult situation for Terraform implementations because they cause constant drift. 

Timestamps and other time-based fields aren’t predictable:

```
settings {
  setting {
    name = "index.creation_date"      # Timestamp varies
    value = "1643651976221"           # Unix timestamp changes
  }
}
```

The [Alerting Rules API](https://www.elastic.co/docs/api/doc/kibana/operation/operation-post-alerting-rule-id) is another example, where execution status data changes on every read:

```
"execution_status": {
  "status": "active", 
  "last_execution_date": "2023-12-07T22:36:41.358Z",  // Changes on every read
  "last_duration": 736
}
```

Users see Terraform detecting "changes" on every refresh, even when nothing in their configuration has actually changed\!

An alternative is to separate volatile runtime data from stable configuration data in responses: 

```json
{
  "config": {
    "name": "my-alert",
    "enabled": true,
    "params": {...}
  },
  "runtime_info": {
    "last_execution": "2023-12-07T22:36:41.358Z",
    "execution_count": 42
  }
}
```

Volatile fields create a challenging choice: include them (causing constant configuration drift) or exclude them (losing valuable runtime information). 

Including and separating them makes it easier for the TF provider to specifically ignore sets of fields (marking them as [readonly](https://registry.terraform.io/providers/elastic/elasticstack/latest/docs/resources/kibana_alerting_rule#read-only)) but needs to be built into the client generator.

#### Keep Fields Isomorphic

**Changing Field Types Break Terraform**

Terraform expects fields to maintain the same data type throughout a resource's lifecycle. When a field that was once a string suddenly becomes an array or object, it forces breaking changes that disrupt existing user configurations.

THis is exactly what happened when Elasticsearch APIs [changed field types](https://github.com/elastic/terraform-provider-elasticstack/issues/926):

```terraform
# Version 1.0 - field was a string
resource "elasticstack_transform" "example" {
  group_by = "field_name"  # String type
}

# Version 2.0 - same field became an array  
resource "elasticstack_transform" "example" {
  group_by = ["field_name"]  # Array type - BREAKING CHANGE!
}
```

This change broke every existing Terraform configuration using that field.

**Design for Consistency**

If your API needs to support multiple data types for the same logical concept, consider these approaches:

1. **Use separate, clearly named fields**
   ```json
   {
     "group_by_field": "field_name",      // Single field
     "group_by_fields": ["field1", "field2"]  // Multiple fields
   }
   ```

2. **Use the most flexible type from the start**
   ```json
   {
     "group_by": ["field_name"]  // Always an array, even for single values
   }
   ```

**When You Must Support Flexible Types**

If polymorphic behavior is unavoidable, JSON strings provide a workaround—but use them sparingly:

```terraform
resource "elasticstack_elasticsearch_index" "example" {
  # Structured fields for simple, predictable values
  number_of_shards   = 1
  number_of_replicas = 2
  
  # JSON strings only for truly complex, variable structures
  mappings = jsonencode({
    properties = {
      user = { type = "keyword" }
      timestamp = { type = "date" }
    }
  })
}
```

[Index Resource Schema](https://github.com/elastic/terraform-provider-elasticstack/blob/main/internal/elasticsearch/index/schema.go)

**Why JSON Strings Are a Last Resort**

While Terraform provides `jsonencode()` and `jsondecode()` functions to handle JSON strings, they come with significant downsides:

- **Limited validation**: Terraform can only validate JSON syntax during plan, not the actual content structure
- **Poor user experience**: Users lose autocompletion, type checking, and clear error messages
- **Complex validation logic**: Content validation is left to the API layer, leading to runtime errors that could have been plan-time validation

**Bottom Line**

Consistent field types make everyone's life easier—API consumers, Terraform provider developers, and your future self. When designing your API, choose field types that can accommodate future needs rather than changing them later.

#### Make Requests Transactional

Terraform expects changes to take effect immediately. Design your API so that changes take effect immediately upon successful response.

Consider the scenario:

A user wants to create alerting rules with different configurations, depending on the space they are in.

In Kibana’s UI, they’d create a space, change into that space and then create the rule.  

Through curl, the flow would be similar, although they’d probably GET the space to make sure it exists before POSTing the rule. 

In terraform, it’s different. Both resources can (and often are) configured at the same time! In the scenario above, the client [needs the space ID](https://github.com/elastic/terraform-provider-elasticstack/blame/0826f4385a29fa58a79f785249f204e13ee3d47c/internal/clients/kibana/alerting.go#L192) to create the rule:

```go
req := client.CreateRuleId(ctxWithAuth, rule.SpaceID, rule.RuleID).KbnXsrf("true").CreateRuleRequest(reqModel)
```

When requests aren’t transactional, we’d need to build the POST & GET workflow into the client, adding complexity to what could have been simple.

Make sure this is the case by, for example,  [setting \`refresh: wait\_for\`](https://github.com/elastic/kibana/blob/188669773e9cc1981b5e89f24afcfdc379ad3058/x-pack/platform/plugins/shared/alerting/server/alerts_client/alerts_client.ts#L644-L657) on the relevant indices in POST requests.

```ts
private async persistAlertsHelper() {
  ...
  await resolveAlertConflicts({
    logger: this.options.logger,
    esClient,
    bulkRequest: {
      refresh: 'wait_for', // Ensure the index is refreshed after the operation
      index: this.indexTemplateAndPattern.alias,
      require_alias: !this.isUsingDataStreams(),
      operations: bulkBody,
    },
    bulkResponse: response,
    ruleId: this.options.rule.id,
    ruleName: this.options.rule.name,
    ruleType: this.ruleType.id,
  });
  ...
}

```

#### Offer Compare-and-Swap

Between refreshing state and applying changes, there’s a gap where someone could modify your API. Generally it's ok to take the approach of last-write-wins. 

If you have to consider case that need concurrency control, support mechanisms like ETags, checksums or, in the case of saved objects, the \`version\` property.

#### Ignore the Robustness Principle: Don’t Normalize Output

The robustness principle says to accept input in various formats but return output in a consistent format, for example converting strings to lowercase, ordering elements in a list or changing whitespace in \`json\` strings.

For Terraform, don’t do this. 

Terraform does byte-for-byte comparisons, so normalized output forces provider developers to implement logic to handle different data formats, ordering, capitalization variations and other unnecessary complexity.

Fortunately, the kibana client hasn’t needed to handle complex normalization yet. Let’s keep it that way, return data exactly as you received it.

Follow these tips, and you’ll make your API a dream to work with for Terraform provider developers.

### Examples

#### Spaces

[AOS](https://www.elastic.co/docs/api/doc/kibana/v9/operation/operation-get-spaces-space-id)  
[Terraform provider](https://github.com/elastic/terraform-provider-elasticstack/blob/main/examples/resources/elasticstack_kibana_space/resource.tfhttps://github.com/elastic/terraform-provider-elasticstack/blob/main/examples/resources/elasticstack_kibana_space/resource.tf)

```
GET /api/spaces/space/{id}
```

```
curl \
 --request GET 'http://localhost:5622/api/spaces/space/{id}' \
 --header "Authorization: $API_KEY" \
 --header "elastic-api-version: 2023-10-31"
```

Response (200)

```
{
  "id": "test_space", <1>
  "name": "Test Space", <2>
  "color": null,
  "imageUrl": "",
  "initials": "ts", <5>
  "solution": "es",
  "description": "A fresh space for testing visualisations", <3>
  "disabledFeatures": [ingestManager", "enterpriseSearch"] <4>
}
```

Terraform resource specification

```
provider "elasticstack" {
  kibana {}
}

resource "elasticstack_kibana_space" "example" {
  space_id          = "test_space" <1>
  name              = "Test Space" <2>
  description       = "A fresh space for testing visualisations" <3>
  disabled_features = ["ingestManager", "enterpriseSearch"] <4>
  initials          = "ts" <5>
}
```

